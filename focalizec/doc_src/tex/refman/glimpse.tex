% $Id: glimpse.tex,v 1.16 2012-10-30 12:27:54 pessaux Exp $
\def\bbbn{{\rm I\!N}} % [EJ] Sinon il y a \mathbb{N} qui fait ça bien aussi...
\label{glimpse}
Before entering the precise description of {\focal}, we give an
informal presentation of its main features, to help further reading of the
reference manual. Every construction or feature that we sketch here is
entirely and precisely described in the following chapters.

\section{The Basic Brick}

The primitive entity of a {\focal} development is the
{\em species}. It can be viewed as a record grouping ``things'' related
to the same concept. Like in most modular design systems (i.e. objected
oriented, algebraic abstract types), the idea is to group a data
structure with the operations that operate on it. Since in {\focal} we don't
only address data type and operations, these ``things'' also
comprise the declaration (or specification) of the operations,  their
stated properties (which represent the requirements for the operations), and the
proofs of these properties.

We now informely describe each of these ``things'', called the {\em methods}
of the species.

\begin{compact-itemize}
  \item The
    {\tt representation} gives the data representation of the entities
    manipulated by the {\em species}. It is a type
    defined by a type expression.
    The {\em representation} definition may be deferred,
    which means that the structure of the embedded data-type
    does not  need to be known at this point. In this case, it is
    simply a type variable.  However, to finally obtain an
    implementation,  the {\em representation}
    has to be defined at some point, either by setting
    {\tt representation = type\_exp} where {\tt  type\_exp} is a type
    expression or by inheritance (see below).
    Type expressions in {\focal} are roughly speaking the ML type expressions (variables,
    basic types, inductive types, record types).
%     {\em species representation types}, denoted by keyword {\tt Self}
%     inside the species and by  the name of their {\em species}
%     outside of them.

    Each {\em species} has a unique {\em representation}. This
    is not a restriction compared to other languages where
    programs/objects/modules can own several private variables
    representing the internal state, since the variables define some part of
    the data structure of the entities manipulated by the
    program/object/module.
    The equivalent {\focal} {\em representation} is simply a tuple grouping
    in one place all these variables that were disseminated in the entire
    program/object/module.


  \item Declarations are composed of the keyword {\tt signature}
    followed by a name and a type. They announce a {\em method} to
    be defined later (the type of the method is given but the implementation
    is still omitted).
%    for specification or design purposes since declared names may be
%    used  to define others {\em methods} while
    Once a method is declared, this method can be used in the text following
    the declaration, in particular in the definition of other methods:
    indeed, the type provided by the {\em signature} allows the {\focal} compiler to check
    that the method is consistently used in all contexts with a type compatible with the
    declared type. Furthermore, the late-binding and the collection mechanisms
    introduced below, ensure that the definition of the method is
    known when the method is effectively invoked.

  \item Definitions are composed of the keyword {\tt let}, followed
    by a name, an optional type, and an expression. They serve to introduce
    constants or functions, i.e. computational operations. The core
    language used to implement them is roughly ML-like expressions
    (let-binding, pattern matching, conditional, higher order
    functions, \ldots) with the addition of a construction to call a
    {\em method} from a given {\em species}. Mutually recursive
    definitions are introduced by {\tt let rec}.



  \item Property statements are composed of the keyword {\tt property}
    followed by the name of the property and its definition, a first-order formula.
    A {\em property} may serve to express requirements
    (i.e. a fact that the system must hold to conform to the Statement
    of Work) and in this case we can view the property as a
    specification purpose {\em method}, like a {\em signature} was for
    {\tt let}-{\em method}s. A property induces a {\em proof obligation} to
    be discharged at some point in the development. A {\em property} may also
    be used to express some ``quality'' information of the system (soundness,
    correctness, \ldots) also submitted to a proof obligation.
    The formulae % [EJ] Pas compris quality information
    are written with the usual logical connectors, universal and
    existential quantifications over a {\focal} type, and cite the name of
    any {\em method} known within the {\em species}' context. For instance,
    a {\em property} telling that for any vehicle, if the speed is non-null,
    then the doors cannot be opened could look like:
    \begin{center}
    {\tt all m in Self, !speed(m) <> Speed!zero -> \tilde doors\_open(m)}
    \end{center}
    In the same way as {\em signatures}, a yet to be proved {\em property}
    can be used as an hypothesis in the proof of other properties or
    theorems.
    Once more, the {\focal} late binding and collection mechanisms ensure
    that the proof of a {\em property} will be ultimately done.

  \item Theorems ({\tt theorem}) made of a  name, a statement and a
    proof are {\em properties} packed with the formal proof that their
    statement holds in the context of the {\em species}. The proof
    accompanying the statement will be processed by {\focal}, {\zenon} and
    ultimately checked with the {\coq} theorem prover.

\end{compact-itemize}

Regarding properties and theorems, note that like in any formal development,
the difficulty may be more to express a true, interesting and meaningful
statement, than to prove it. For instance, claiming that a piece of software
is ``formally proved'' because it respects a safety requirement is
meaningless if the statement of this requirement is trivially true
(see \cite{traps} for examples).
%      system\_ok}. This is obviously a non-sense since the text of the
%    property is trivial and does not link {\tt system\_ok} with the
%    rest of the software (see \cite{traps} for less trivial examples).

Let's illustrate these notions on an example that we incrementally
extend. We want to model some simple algebraic structures. Let's start
with the description of a ``setoid'' representing the data structure of
``things'' belonging to a set, which can be submitted to an
equality test and exhibited (i.e. one can get a witness of existence of one
of these ``things'').

{\scriptsize
\begin{lstlisting}
species Setoid =
  signature ( = ) : Self -> Self -> bool ;
  signature element : Self ;

  property refl : all x in Self, x = x ;
  property symm : all x y in Self, x = y -> y = x ;
  property trans: all x y z in Self, x=y and y=z -> x=z ;
  let different (x, y) = basics#not_b (x = y) ;
  theorem different_irrefl : all x in Self, ~different(x, x)
   proof = by definition of different
              property refl ;
end ;;
\end{lstlisting}}

In this {\em species},  the {\em representation} is not explicitly
given (the keyword {\tt representation} is not used), since we don't need to set
it to the express functions and properties that a ``setoid''
requires. However, we can refer to the representation via {\tt Self}
(in this case a type variable). In the same way, we just specify a {\em
signature} for the equality (operator {\tt =}). We introduce the three
properties that the equality must have (exactly the properties of an equivalence
relation).

We complete the example by the definition of
the function {\tt different} which uses the (not yet defined) {\tt =} method,
and the predefined boolean negation {\tt basics\#not\_b}.

Not only we can define {\tt different} out of a not yet defined method {\tt
=}, we can also prove a property of {\tt different} based on
the not yet proved properties of {\tt =}! Indeed we prove that
{\tt different} is irreflexive, under the hypothesis that {\tt =} is an
equivalence relation (i.e. that any implementation of {\tt =} used by
{\tt different} will satisfy these properties).

Note: {\tt basics\#not\_b} stands for the function {\tt not\_b} defined in
the {\focal} {\tt basics} development (which is in the source file {\tt
basics.fcl} of the standard library).

\bigskip

In {\focal}, the {\em late-binding} feature makes it possible to use {\em
methods} as soon as they have been declared and way before they get a
real {\em definition}. Similarly, {\focal} allows arbitrary {\em method}
redefinition: the effective {\em definition} of the method
inside a species is guarrantied to be the last version of the successive
definitions of the method.

\section{Type of Species, Interfaces and Collections}
\label{species-type}
\label{species-interface}
The {\em type} of a {\em species} is obtained by removing all the definitions
and proofs. Thus, it is somoe kind of record type, made of all the method
types of the species. If the {\tt representation} is still a type
variable say $\alpha$, then the {\em species} type is prefixed with an
existential binder $\exists \alpha$. This binder is eliminated as
soon as the {\tt representation} is known.
Technically, the existancial type variable is instantiated when the
representation type is defined; furthermore, the compiler checks that
all existancial type variables have been eliminated before the generation of
runnable code.

\bigskip

The {\em interface} of a species is obtained by abstracting the {\em
representation} type in the {\em species type}; this abstraction
is permanent.

\bigskip

{\bf Warning} {\em  No special construction
is given to denote the interface of a species in the concrete syntax,
it is simply denoted by the name of the species.} Do not
confuse a species and its interface.

\bigskip

The {\em species type} remain totally implicit in the concrete syntax, being
just used as a step to build the {\em species interface}. It is used
during inheritance resolution.

Interfaces can be ordered by inclusion, a point providing a very
simple notion of subtyping. This point will be further commented.


A species is said to be {\em complete} when the representation and all the
declarations have received a definition and all the properties have received
a proof.

When {\em complete}, a species can be submitted to an abstraction process of
its representation to create a {\em collection}. Put it the other way round:
a collection abstracts a complete species. Thus, the {\em interface} of a
collection is the {\em interface} of the abstracted complete species. Thus, a
collection is a kind of abstract data type, only usable through
the methods of its interface, with the addional guarantee that all the
declarations have been defined and all the statements have been proved.


\section{Combining Bricks by Inheritance}

A {\focal} development is organised as a hierarchy which may have
several roots. Usually the upper levels of the hierarchy are built
during the specification stage while the lower ones correspond to
implementations. Each node of the hierarchy, i.e. each {\em species},
is a progress towards a complete implementation. On the previous
example, putting aside {\tt different},  we typically presented a kind of
{\em species} for ``specification'' since it expresses only
{\em signatures} of functions to be later implemented and properties
to be later proved.

We can now create a new {\em species} by {\bf inheritance} of an already
defined one. We can make this new species more ``complex'' by adding new
operations and properties, or we can make it more concrete by providing
definitions to {\em signatures} and proofs to {\em properties}, without
adding new features.

Hence, the {\focal} inheritance notion serves two kinds of evolutions in the
development process. The first kind of evolution is {\em additional
complexity}: the inheritance makes more complex {\em species} out of simpler
ones; the new species gets more operations than its parents
(keeping the ancestors operations or possibly redefining some of them, if
required).
The second kind of inheritance is {\em refinement}: the new
species has less and less still unknown parts; it tends to the status of a ``runnable''
implementation, providing explicit definitions to the {\em methods} that were
previously only declared.

Continuing our example, we want to extend our model to represent
``things'' with a multiplication and a neutral element for this
operation.

{\scriptsize
\begin{lstlisting}
species Monoid =
  inherit Setoid;
  signature ( * ) : Self -> Self -> Self ;
  signature one : Self ;
  let element = one * one ;
end ;;
\end{lstlisting}}

{\em Monoid} are ``things'' that are {\em Setoids} but also have an operation
{\tt *} and a specific value called {\em one}; besides the new {\em methods}
we also gave a definition to {\tt element}, saying it is the application of
the method {\tt *} to {\tt one} twice, both of them being only {\em
declared}. Here, we used the inheritance in both the presented ways: making a
more complex entity by adding {\em methods} and getting closer to the
implementation by explicitly defining {\tt element}.

{\focal} provides multiple inheritance. For sake of simplicity,
the above example uses simple inheritance. When inheriting the same
{\em method} from more than one parent, the order of parents apparition in the
{\tt inherit} clause serves to determine the chosen {\em method} (only
the latest definition of any method appearing several times in the
list of inherited species is retained).

The {\em type} of a {\em  species} built using inheritance is defined
like for other {\em species}, the {\em method} types being those of the {\em
methods} appearing in the {\em species} after inheritance resolution.

A strong constraint in inheritance is that the type of inherited,
and/or redefined {\em methods} cannot change.  This is required to
ensure consistency of the {\focal} model, hence of the developed
software. More precisely, if the representation is given by a type
expression containing some type variables, then it can be more defined
by instanciation of these variables. In the same way, two signatures
have compatible types if they have a common unifier; thus, roughly
speaking, if they are compatible as ML-like types. For example, if the
representation was not yet defined (thus being still a type variable),
it can be defined by {\tt int}. And if a species $S$ inherits from
$S_1$ and $S2$ a method called $m$, there is no type clash if $S_1 !m$
and $S_2!m$ can be unified, then the method $S!m$ is addigned the most general
unifier of these two types.

In a nutshell, if a species {\em B} inherits from a species {\em A}, the
intuition is that any instance of {\em B} is also an instance of {\em A}.

\section{Combining Bricks by Parameterisation}

As indicated, inheritance is used to enrich or to implement {\em species}.
However, we sometimes need to use a {\em species}, not to take over
its {\em methods}, but rather to use it as an ``ingredient'' to build
a new structure. For instance, a product of setoids is a
new structure, using the previous {\em species} as the ``ingredient''.
Indeed, the structure of a product is not similar to any of its component,
but is build using the structures of its components. A product
can be seen as {\em parameterised} by its two components.
Following this idea, {\focal} allows two flavors of parameterisation.

\subsection{Parameterisation by Collection}

We first introduce the {\em collection parameters}. They are
{\em collections} that the hosting species may use through their
{\em methods} to define its own ones.


A {\em collection parameter} is given a name $C$ and a (species) interface
$I$.  The name $C$ serves to call the {\em methods} declared in
$I$. Intuitively, $C$ will at some stage be implemented by a collection $CE$
whose interface contains the methods of the interface $I$.  Moreover, the
collection and late-binding mechanisms ensure that all methods appearing in
$I$ are indeed implemented (defined for functions, proved for properties) in
$CE$. Thus, no runtime error, due to linkage of libraries, can occur and any
{\em property} or {\em theorem} stated in $I$ can be safely used as an
hypothesis.

Calling a {\em species}'s {\em method} is
done via the ``bang'' notation:
{\tt !meth} or\break{}{\tt Self!meth} for a {\em method} of the current
{\em species} (and in this case, even simpler: {\tt meth}, since the
{\focal} compiler will resolve scoping issues). To call
{\em collection parameters}'s {\em method}, the same notation is used:
{\tt A!element} stands for the {\em method} {\tt element} of the
{\em collection parameter} {\tt A}.


To go on with our example, a product of setoids has two components, hence a
{\em species} for products of setoids has two {\em collection parameters}. It
is itself a setoid (that is, a ``thing'' with an equality), a fact which is
simply recorded via the inheritance mechanism: {\tt inherit Setoid} gives to
{\tt Setoid\_product} all the methods of {\tt Setoid}.

{\scriptsize
\begin{lstlisting}
species Setoid_product (A is Setoid, B is Setoid) =
  inherit Setoid;

  signature fst : Self -> A ;
  signature snd : Self -> B ;
  signature pair : A -> B -> Self ;

  let element = Self!pair(A!element, B!element) ;

  let ( = ) (x, y) = basics#and_b (A!( = )(fst(x), fst(y)),
                                   B!( = )(snd(x), snd(y))) ;
  proof of refl = by definition of ( = )
                     property A!refl, B!refl ;

end ;;
\end{lstlisting}}

We first declare methods {\tt fst}, {\tt snd} and {\tt pair} to represent the
two projections and the construction of pairs.
Next, we introduce a definition for {\tt element} by building a pair, using
the function  {\tt pair} applied to the method {\tt element} of respectively {\tt A}
and {\tt B}. We also add a definition for {\tt =} of {\tt Setoid\_product},
relying on the methods {\tt =} of {\tt A} and {\tt B}
(which are not yet defined), and we prove that {\tt =} of {\tt Setoid\_product} is
indeed reflexive, upon the hypothesis made on {\tt A!( = )}
and {\tt B!( = )}.  The part of {\focal} used to write proofs will be
shortly presented later, in section \ref{focal-proof-language}.

Such a species can be refined with {\tt representation = A * B}, indicating
that the representation of the product is the Cartesian Product of the
representation of the two parameters. In {\tt A * B}, {\tt *} is the {\focal}
type  constructor of pairs, {\tt A} denotes indeed the representation of the
first {\em collection parameter}, and {\tt B} the one of of the second {\em
collection parameter}.

This way, the {\em species} {\tt Setoid\_product} builds its {\em
methods} relying on those of its {\em collection parameters}. Note the
two different uses of {\tt Setoid} in our {\em species} {\tt
Setoid\_product}, which both inherits of and is parameterised by it.

\bigskip

Why {\em collection parameters} and not simply {\em species parameters}?
There are two reasons. First, effective parameters must provide
definitions/proofs for all the methods of the required interface: this is the
contract. Thus, effective parameters must be {\em complete} species. Then, we
do not want the parameterisation to introduce dependencies on the parameters'
{\em representation} definitions. For example, it is impossible to express ``
if {\tt A!representation} is {\tt int} and {\tt B!representation} is {\tt
bool} then {\tt A * B} is a list of boolean values''. This would dramatically
restrict the possibilities to instantiate parameters since assumptions on the
{\em representation}, possibly used in the parameterised {\em species} to
write its own {\em methods}, could prevent {\em collections} having the right
set of {\em methods} but a different representation to be used as effective
parameters. Such a behaviour would make parameterisation too weak to be
usable. We choose to always hide the {\em representation} of a {\em
collection parameter} to the parameterised hosting {\em species}. Hence the
introduction of the notion of {\em collection}, obtained by abstracting the
representation from a complete species.

\subsection{Parameterisation by Entity (Value)}

Let us imagine we want to make a {\em species} to implement arithmetic on
natural numbers modulo a certain value. In the expression $5 {\tt\ modulo\ }
2\ is\ 1$, both $5$ and $2$ are natural numbers. To be sure that the {\em
species} will consistently work with the same modulo, this last one must be
embedded in the {\em species}. However, the {\em species} itself doesn't rely
on a particular value of the modulo. Hence this value is clearly a {\bf
parameter} of the species, but a parameter for which need its {\bf value},
not only by its {\em representation} and the methods acting on it. Such a
parameter is named an {\em entity parameter}. Being a value, an entity
parameter belongs to some collection, and this collection must also be declared as a {\em
collection parameter} of the species. An entity parameter denotes a
{\em value} having the type of the {\em representation} of its associated
{\em collection parameter}.

As an exemple, let us define a collection {\tt Modulo\_n}. We first define a
{\em species} to represent natural numbers:

{\scriptsize
\begin{lstlisting}
species NatModel =
  signature one : Self ;
  signature inc : Self -> Self ;
  signature modulo : Self -> Self -> Self ;
end ;;
\end{lstlisting}}

Note that {\tt NatModel} can be later implemented in various ways, using
Peano's integers, machine integers, arbitrary-precision arithmetic (as well
as things that are not really integers, our specification being too
simplistic)\ldots

The {\em species} ``working modulo n\ldots'' now embeds the value of {\tt n}
as an element of a collection for {\tt NatModel}:

{\scriptsize
\begin{lstlisting}
species Modulo_n (Naturals is NatModel, n in Naturals) =
  let job1 (x : Naturals) =
    ... Naturals!modulo (x, n) ... ;
  let job2 (x : Naturals, ...) =
    ... ... Naturals!modulo (x, n) ... ... ;
end ;;
\end{lstlisting}}

Using the {\em entity parameter} {\tt n}, we ensure that the
{\em species} {\tt Modulo\_n} works for {\em any} value of the
modulo, but will always use the {\em same} value {\tt n} of the modulo
everywhere inside the {\em species}.


\section{The Final Brick}

As briefly introduced in \ref{species-interface}, a {\em species} needs to be
complete to lead to executable code for its functions and checkable proofs
for its theorems. When a {\em species} is complete, it can be turned into a
{\em collection}. Hence, a {\em collection} represents the final stage of the
inheritance tree of a {\em species} and leads to an effective data
representation with executable functions processing it.

For instance, providing that the previous {\em species} {\tt NatModel} has
been refined into a fully-defined species {\tt MachineNativeInt} through
inheritances steps, with a {\em method} {\tt from\_string} allowing to create
the natural representation of a string, we could get a related collection by:

{\scriptsize
\begin{lstlisting}
collection MachineNativeIntegers =
  implement MachineNativeInt;
end ;;
\end{lstlisting}}

Next, to get a {\em collection} implementing arithmetic modulo $8$, we
can define a {\em collection} for the {\em species} {\tt Modulo\_n}:

{\scriptsize
\begin{lstlisting}
collection Modulo_8 =
  implement Modulo_n
    (MachineNativeIntegers, MachineNativeIntegers!from_string ("8");
end;;
\end{lstlisting}}

As exemplify here, a species is applied to effective parameters by giving
their values with the same syntax as for parameter passing.

As said before, to ensure modularity and abstraction, the {\em
representation} of a {\em collection} is hidden (as well as its
definitions). It means that any software component using a {\em collection}
will only be able to manipulate its values through the operations ({\em
methods}) that the collection provides via its interface.  As a corollary, no
other software component can possibly break the invariants required by the
internals of a {\em collection}.

\section{Properties, Theorems and  Proofs}
\label{focal-proof-language}

{\focal} not only provides a way to write programs, it also intends to
encompass both the executable model (i.e. program) and the properties that
this model must satisfy. For this reason, some ``special'' fields of the
species only deal with logic instead of specifying purely behavioural aspects
of the program: those logical aspects are {\em theorems}, {\em properties}
and {\em proofs}.

Stating a {\em property} declares that a {\em proof} that the property {\bf
holds} will be given at some stage of the development. The {\em theorems} are
properties for which the {\em proof} is given with the statement. All the proofs must be
done by the developer; the compiler ultimately send them to the {\coq} proof assistant
for verification: all the demonstrations made in {\focal} are automatically
machine checked for consistency by {\coq}.

{\focal} provides several ways to write proofs. The normal and encouraged way
is to use the {\focal}'s proof language to write the proofs.  The {\focal}'s
proof language (or {\em FPL} for short), is a hierarchical proof language
especially designed to give an easy way to vary the grain of the proof, from
rough sketch to fully detailed proof. As in the usual mathematical activity,
the idea is to provide hints and direction for a proof and let the reader
complete the details. Well, don't panic: you will not have to complete the
proofs of all the {\focal} development you may ever read or write! The proofs
in {\focal} do not require a human being to read them and complete their
numerous omitted details! The {\focal} system delegates this burden to a
companion program: the {\zenon} proof finder.

From the hints given in the {\focal} development, {\zenon} attempts to
generate a complete proof and exhibit a {\coq} proof term suitable for
verification. So far so good! But what happens if {\zenon} fails to find the
(complete) proof ? Well, you can consider this failure as a hint that the
given proof was too sketchy: you have to develop it a bit, for instance by
stating and proving some intermediate lemmas or by detailing the proof path!
Once again, this is rather natural and not so far from normal mathematical
activity.

{\zenon} \cite{ZenonBDD,zenon0.4.1} is developed by D. Doligez. It is
a first order theorem prover based on the tableau method incorporating
implementation novelties such as sharing.

The {\focal} programmer gives basic hints to {\zenon} such as: ``prove by definition
of this {\em method}'' (i.e. look inside the body of the method) or ``prove
by this {\em property}'' (i.e. use the logical statement of a {\em theorem}
or {\em property} already proven). This hint mechanism is embedded into the
entire FPL description of the proof into steps stating assumptions (that must
obviously be demonstrated afterwards) in order to prove some lemmas or parts of
the property at hand.

We now give such a demonstration.

{\scriptsize
\begin{lstlisting}
  theorem order_inf_is_infimum : all x y i : Self,
    !order_inf(i, x) -> !order_inf(i, y) ->
      !order_inf(i, !inf(x, y))
    proof =
      <1>1 assume
             x : Self, y : Self, i : Self,
             hypothesis H1 : !order_inf (i, x),
             hypothesis H2 : !order_inf (i, y),
           prove !order_inf (i, !inf (x, y))
        <2>1 prove !equal (i, !inf (!inf (i, x), y))
          by hypothesis H1, H2
             property inf_left_substitution_rule,
               equal_symmetric, equal_transitive
             definition of order_inf
        <2>f qed
          by step <2>1
             property inf_is_associative, equal_transitive
             definition of order_inf
      <1>f conclude
    ;
\end{lstlisting}}

The important point is that {\zenon} works for the developer: {\bf it
searches and completes the proof} for the developer that no more have to
elaborate the proof completely formally ``from scratch''.

Like all other automatic theorem prover, {\zenon} may fail to find a
demonstration. In this case, {\focal} allows the developer to write verbatim {\coq}
proofs. Comfort of automation is lost in favor of an increase in expressive power:
the entire {\coq} vernacular language is now available to the developer to
write the proof.

Finally, the {\tt assumed} keyword is the ultimate proof backdoor: the proof
is not given and the property is admitted. Obviously, a safe development
should not make a liberal usage of this feature, since {\tt assumed} bypasses
the formal verification of the software's model. However, such a functionality
remains needed for various reasons. For example, a development may be linked
with external code; the properties of the {\focal} code now depends on properties
of the external code; to continue the development as safely as possible, it
is necessary to carefully state the properties that are assumed for the
external code and go on providing properties and proofs about the program:
those proofs will give valuable confidence, even if they only hold if the set
of assumptions for the external code is valid.

% [EJ] L'utilisateur saura quand utiliser assumed, mais l'exemple donne me semble
% inapproprie. En effet, l'exemple x+1>x est justement faux pour les entiers
% machine, et il ne devrait pas etre admis de maniere generique. Ce sera sans doute
% le choix de certains developpeurs de l'admettre, mais c'est hors du scope du manref

\section{Around the Language}

In the previous sections, we presented {\focal} through its programming model
and shortly its syntax. We especially investigated the various entities
making a {\focal} program. We now address what becomes a {\focal} program
once compiled. We recall that {\focal} supports the redefinition of
functions, which permits for example to specialise the code to a specific
representation of data (for example, there exists a generic implementation of
integer addition modulo {\tt n} but this implementation can be redefined in
arithmetics modulo {\tt 2}, if boolean values are used to represent the two
values). In summary, {\focal} is also a very convenient tool to maintain
software.

\subsection{Consistency of the Software}

All along the {\focal} development cycle, the compiler keeps trace of
dependencies between {\em species}, {\em methods}, and {\em proofs} \ldots to
ensure that all the modifications are consistently propagated to any place
that needs to be changed.

{\focal} deals with two types of dependencies:
\begin{compact-itemize}
\item The {\bf decl}-dependency: a {\em method} $A$ decl-depends on a
  {\em method} $B$, if the {\bf declaration} of $B$ is required to
  state $A$.
\item The {\bf def}-dependency: a {\em method} (and more especially, a
  {\em theorem}) $A$ def-depends on a {\em method} $B$, if the
  {\bf definition} of $B$ is required to state $A$ (and more
  especially, to prove the property stated by the {\em theorem}
  $A$).
\end{compact-itemize}

The redefinition of a function may invalidate the proofs that use the
properties of the body of the function. All the proofs which truly depend of
the definition are then invalidated by the compiler and must be done again in
the updated context where the function gets the new definition. Thus, choose
the proper level in the hierarchy to do a proff is a major practical
difficulty. In \cite{PrevostoJaume2003}, Prevosto and Jaume propose
a \emph{coding style} to minimise the number of proofs to be redone in case
of redefinition, by using a certain kind of modularisation for the proofs.

\subsection{Code Generation}

{\focal} currently compiles programs toward two languages, {\ocaml} to
get an executable standalone, and {\coq} to have a formal model
of the program, with theorems and proofs entirely machine checked.

In the {\ocaml} code generation, all the logical aspects are discarded since
they do not lead to executable code.

In contrast, in {\coq}, all the {\em methods} are compiled,
i.e. ``computational'' {\em methods} and logical {\em methods} with their
proofs. This allows {\coq} to check the entire consistence of the system
developed in {\focal}.


\def\focaltest{FocalTest}

\subsection{Tests}
{\focal} incorporates a tool named {\em \focaltest}
\cite{CarlierDuboisLNCS2008} for Integration/Validation testing. It
allows to confront automatically a property of the specification with an
implementation. It automatically generates test cases, executes them and
produces a test report as an XML document. The property under test is used to
generate the test case but also as an oracle. When a test case fails, it
means that a counterexample of the property has been found: the
implementation does not match the property. This surely points out an
inconsistency, due to a problem in the code or in the specification.

The tool {\em \focaltest} automatically produces the test environment and
the drivers to conduct the tests.  It benefits from the inheritance
mechanism to isolate the testing harness from the components written
by the programmer.

The testable properties are required to be broken down into a precondition
and a conclusion, both executable. The current version of {\em \focaltest}
proposes a pure random test cases generation: a test case is generated, if it
satisfies the pre-condition then the verdict of the test case is obtained by
executing the post-condition.  For some form of preconditions the test
generation process can be computationally challenging. To overcome this
drawback, a constraint based generation is under development: it would allow
to directly produce test cases that satisfy the precondition.


\subsection{Documentation}

The {\focdoc} tool \cite{MaarekCalculemus03} is a documentation generator.
The documentation is automatically extracted from the {\focal} source, hence
the documentation of a component is always in par with its implementation.

{\focdoc} uses its own XML format that contains information coming not only
from programmer added structured comments (that are parsed and kept in the
program's abstract syntax tree) and from the {\focal} concrete syntax but
also from the results of the type inference and dependency analysis. From
this XML representation and thanks to some XSLT stylesheets, {\focdoc}
generated a bunch of HTML or {\LaTeX} files. The generated documentation
cannot be considered as a complete safety case; however, it can helpfully
contribute to the elaboration of the safety case. In the same way, it is
possible to produce UML models~\cite{Focal-UML} as means to provide a
graphical documentation for the {\focal} specifications. The use of graphical
notations appears quite useful when interacting with end-users, as these tend
to be more intuitive and are easier to grasp than their formal (or textual)
counterparts. This transformation is based on a formal schema and captures
every aspect of the {\focal} language, so that it has been possible to prove
the soundness of this transformation (semantic preservation).

The {\focal} compiler's architecture is designed to easily plug third-parties
analyses that can benefit from the internal structures elaborated by the
compiler from the source code. This allows, for instance, to make dedicated
documentation tools for custom purposes, just exploiting the information
stored in the {\focal} program's abstract syntax tree, or the extra
information added by some external processes or specialized analyses.
