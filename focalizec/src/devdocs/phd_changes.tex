% $Id: phd_changes.tex,v 1.11 2009-05-28 08:43:26 pessaux Exp $
\subsection{Type unification (1)}
\index{unification}
\index{rule![SELF1/2]}
\noindent Section 3.3, definition 9, page 27.

\noindent Rule [SELF1] should be: $mg(t, {\bf Self}, t) = {\bf Self}, id$

\noindent Rule [SELF2] should be: $mg(t, t, {\bf Self}) = {\bf Self}, id$


\subsection{Type unification (2)}
Is the ``preference of {\tt Self}'' (see above) rule really needed ?
It seems it can lead to absence of principal type. C.f. the section
\ref{cadavers}.


\subsection{Normal form algorithm}
\index{normal form}
\noindent Section 3.7.1, page 36.

\noindent In the algorithm, line 10 should be:
$\mathbb{W}_1 \leftarrow ((\psi_{i_{0}} \varogreaterthan \phi), \mathbb{X}).$

\smallskip

\noindent In the algorithm, line 13 should be:
$\mathbb{W}_2 \leftarrow (\mathbb{W}_2, \phi)$.

\smallskip
\noindent In the running text, page 37, line 8, the same modification
must be done to get ``on garde $\psi_{i_{0}} \varogreaterthan \phi$
dans $\mathbb{W}_1$ \ldots''.



\subsection{Typing rules for parametrised species}
\index{rule![COL-PRM]}
\noindent Section 3.8, figure 3.2, page 43.

\noindent Rule [COL-PRM] should be:

\inferrule
  {
  {\cal C}, \Omega \vdash e^S : a \\
  {\cal C} + C : {\cal A} (a, C), \Omega \vdash
    {\bf species}\ S (prms)\ {\bf inherits}\ e^{S}_1, \ldots
    e^{S}_{h_f} = \Phi_1 \ldots \Phi_n : t_S
  }
  {
  {\cal C}, \Omega \vdash {\bf species}\ S(C \ {\bf is}\ e^S, prms)
  \ {\bf inherits}\ e^{S}_1, \ldots e^{S}_{h_f} =
  \Phi_1 \ldots \Phi_n : (C\ {\bf is}\ a)t_S
  }



\subsection{Dependency on the carrier}
\index{dependency!on carrier}
\noindent Section 3.9.4, definition 28, page 50.

\noindent The definition should be: ``Soit une expression $e$, si une
sous-expression de $e$ \rlap{----------}a le type {\bf fait référence à
(``contient'')} {\tt Self}, il y a une
 decl-dépendance
vis-à-vis du type support.''.

\noindent In English: ''Let's have $e$ an expression, if a
sub-expression of $e$ \rlap{-----------}has type {\bf makes reference
to (``contains'')} {\tt Self}, then there is a decl-dependency
on the carrier''.

\medskip
This is more  accurate since an expression having type
${\tt int} \rightarrow {\tt Self}$ does not have type {\tt Self}, but
when we state its type, {\tt Self} occurs in the type and must be
bound somewhere (and the decl-dependency on the carrier is just there
for this purpose).



% MERDE !!! Je ne me souviens plus pourquoi. L'explication que j'ai
% foutue sur la version papier de la thèse est merdique. Bon, à
% investiguer plus tard...
%
% \subsection{Inference rules for logical statements}
% \noindent Section 3.9.5, figure 3.3, page 52.

% \noindent The rule [EXPR] states that one can infer that an expression
% $expr$ has type {\tt prop} in $\Sigma$ if one can infer that is has
% type {\tt bool} in the ``reduced'' $\Sigma^{*}$.
% This is correct in the context of type checking. But this is not exact
% in the context of type {\bf inference}. In fact, it doen't work since
% the rules [EX] and [ALL] need to enter the bound variables 
% And then, we must also allow type {\tt prop} for expressions.



\subsection{Dependencies in a species}
\noindent Section 3.9.5, definition 31, page 53.

\noindent Lines 3 and 4 should be:

\hspace{1cm} $\forall j < n,
   \ y_{j} \in \decldeps{y_{i}}_S \cup \defdeps{y_{j+1}}_S$

\noindent $x_1 <^{def}_{S} x_2 \ \widehat{=}\ \exists \{y_i\}_{i=1\ldots n}
  \ tel\ que \ y_1 \circlearrowright_S x_1, y_n \circlearrowright_S x_2,
  \forall j < n,\ y_j \in \defdeps{y_{j+1}}_S$



\subsection{Parameters used by a method}
\noindent Section 3.9.5, definition 66, page 124.

\noindent To understand the rules {\tt [BODY]}, {\tt [TYPE]},
{\tt [DEF-DEP]}, {\tt [UNIVERS]} and {\tt [PRM]}, it should be stated
that implicitly the parameter $C_{p'}$ has the form:
$$C_{p'} {\tt is/in\ } \tau_{p'}$$.


\subsection{Instanciation of species parameters}
\index{instanciation}
\noindent Section 3.9.5, definition 67, page 124.

\noindent Second rule should be:
\inferrule
  {
  x \Lsh S = S_h \\
  {\cal E}(S_h) = (C_1 \centerdot \tau_1, \ldots,
                   C_{p_f} \centerdot \tau_{p_f}) \\
  l_h = e_1 \ldots\ e_{p_f}
  }
  {
  {\tt Inst}_S (x) = \{ {\tt Inst}_{C_p}(e_p)_{C_p\in {\cal U}_{S_h}(x)}\}
  }



\subsection{Translation example in \ocaml}
\noindent Section 8.2, page 152.

The code sample shown and the explanation about {\tt create} at the
top of the page is wrong or at least not complete. In effect, if
presented this way, we don't know from where {\tt create} comes. In
fact, we must used the one coming from the species we
``implement''. So a qualified notation (i.e. module name + function
name) is required.



\subsection{Dependencies of a method}
\noindent Section 8.3.1, definition 72, page 153.


\subsubsection{Missing notion of order}
All along the rules, dependencies are stated as a set of names. In
fact this is incomplete since there can be dependencies between these
names for a collection parameter. So they must be ordered according to
their own dependencies (i.e. according to def-dependencies inside the
hosting species that is that collection parameter).

\noindent For instance:

\begin{table}[h]
{\footnotesize
\begin{lstlisting}
species S1 ... =
  let eq = ... ;
  theorem th1 : all x in ..., !eq (...) ...
    proof = ... ;
end ;;

species S2 (P is S1) ... =
  theorem th2 : all x in P, ...
    proof = ... property P!th1 ... ;
end ;;
\end{lstlisting}
}
\end{table}

In {\tt S1}, {\tt th1} decl-depends on {\tt eq}. In {\tt S2}, method
{\tt th2} has a dependencies on its collection parameter {\tt P}
methods. Especially, on {\tt P!th1}, and completions rules require to
add {\tt P!eq} (in order to express the ``type'' of {\tt th1},
i.e. its statement). Since in {\tt P},  {\tt th1} decl-depends on
{\tt eq}, when making $\lambda$-liftings to abstract {\tt P}'s methods
in the dependencies on methods of parameters in {\tt S1}, we must
ensure that {\tt eq} is $\lambda$-filter before {\tt th1} otherwise
{\tt eq} will be unbound in {\tt th1}.

This order is given be the dependencies of the methods inside the
species used as collection parameter.


\subsubsection{Missing rule}
The rules [DEF-DEP], [UNIVERS] and [PRM] can add dependencies on
parameters after rule [BODY] and [TYPES]. However, the added methods
can have decl-dependencies via their ``types''. An this is not taken
into account by the current set of rules.
To circumvent, a new rule is added, [DIDOU] (better name to be found,
but the day I thought to this rule, I was very poor in naming schemes
\smiley). This rule intuitively takes the all dependencies found by
[BODY], [TYPES], [DEF-DEP], [UNIVERS] and [PRM] as initial set and
performs a fixpoint by adding for each method of dependencies, its
decl-dependencies coming from its ``type'' (i.e. ML-like type for
computational methods, and statement for logical methods). Of course,
when tracking decl-dependencies of a method, we address the method body
in its species. But this species is a collection parameter. So before
adding the found method to the set of dependencies on collection
parameters of the analysed species, we must replace in the method,
occurrences of {\tt Self} by the by the species parameter from where
this method comes.


\subsubsection{Missing substitution in rule [PRM]}
\index{rule![PRM]}
\label{rule-PRM-corrected}
First, the rule {\tt [PRM]} needs further explanations to understand
its presentation. It must first be understood that in this rule, the
species {\tt S} has the following form:

${\tt species}\ S (C_p\ {\tt is}\ \ldots, C_{p'}\ {\tt is}\ S'(C_p))$

Moreover, implicitly $i_{p'}$ is the interface of $C_{p'}$. And $C_p$
is a valid implementation of the parameter $C'_k$ (having the
interface $i'_k$) of the species $S'$.

\medskip
\noindent Now, the rule says:

\inferrule
  {
  z \in Deps (S, C_{p'})[x] \\
  i_{p'} = S'(e_1, \ldots, C_p, \ldots) \\
  {\cal E}(S') = (C'_1 \centerdot i'_1, \ldots, C'_k\ {\tt is}\  i'_k,\ldots) \\
  y \in Deps (S', C'_k) [z]
  }
  {
  y \in Deps (S, C_p)[x]
  }

\noindent This rule forget to show that we must instantiate the formal
parameter of {\tt S'} by the effective argument provided. In effect,
in the bodies/types of the methods of {\tt S'} (those methods the
conclusion adds to the currently computed dependencies set), parameters
are those of {\tt S'}, not our current ones we use to instantiate the
formal ones of {\tt S'} ! To prevent those of {\tt S'} to remain in
the expressions and be unbound, we do the instanciation here.


\subsubsection{Inconsistency between inherited/re-computed dependencies}
When computing dependencies on collection parameters of a method, it
is never clearly stated about how to compute them when the method is
inherited.

One way is to compute from scratch the dependencies from the body of
the inherited method. The second is to recover the inherited
dependencies and to perform substitution of formal parameters of the
inherited species by effective arguments used in the {\tt inherits}
species expression.

This last process is in fact very difficult due to the amount of
information recorded in the parameters/methods descriptions (moreover,
making severe usage of sharing).

So we really prefer to use the first method that naturally create the
data-structures and information to record. The only problem is that
during inheritance, some dependencies present in the original
inherited species may ``disappear'' due to parameters instantiations.

\noindent For example:

\begin{table}[h]
{\footnotesize
\begin{lstlisting}
species Simple =
   signature equal : Self -> Self -> bool ;
end ;;

species Couple (S is Simple, T is Simple) =
  signature morph: S -> T;
  let equiv(e1, e2) = T!equal(!morph(e1), !morph(e2));
end ;;

species Bug (G is Simple) inherits Couple (G, G) =
  theorem theo: true
    proof =
      <1>1 
         prove true
         <2>f qed assumed {* *}
      <1>2 qed by definition of equiv ;
end ;;
\end{lstlisting}
}
\end{table}

In fact, the problem is that when we compute dependencies on
collection parameters, in the case where we inherit from a species
having 2 parameters instantiated by the same argument, we get into a
fusion of the methods we depend on.

But, the method generator coming from the originally inherited method
expects to be applied to as many arguments that $lambda$-lifting were
created.

In the above example, {\tt S} and {\tt T} are instantiated both by
{\tt G}. So we get 1 dependency on {\tt G!rep} (the carrier) and 1 on
{\tt G!equal} although the method generator expects 3 arguments :
twice {\tt G!rep} and one {\tt G!equal} because in {\tt Couple}
was abstracted on the carrier of {\tt S}, the carrier of {\tt T} and
{\tt T!equal}.
Because we work with sets to represent dependencies, twice
{\tt  G!rep} is \ldots 1 {\tt  G!rep}. And same thing for
{\tt G!equal}. 

We described the problem here via a dependency on the carrier, but
its is the same thing with dependencies on other methods: we would
just need to make {\tt equiv} depending for instance on {\tt S!equal}
and {\tt S!equal}.

The solution is to make a mix between the two initial
solutions. First, we compute the abstractions due to dependencies on
collection parameters in the body of the method once inherited. This
way, we naturally let data-structures be created and sharing what they
need. In fact, this gives us a ``skeleton'' of dependencies where some
$\lambda$-liftings may have disappeared compared to the number of
required in the inherited species. But, we know that all the methods
involved in the dependencies are present, may be not with the right
number of occurrences. Then we take the dependencies scheme of tin
inherited method and we rebuild a final dependencies structure by
replacing in the inherited one all the occurrences of dependencies on
the formal parameter by the corresponding effective argument (used
during instanciation) ones. This way, we just ``remap'' the computed
dependencies on the inherited ones' scheme.

In the example above, this means that we compute in {\tt Bug} that we
have dependencies on {\tt G!rep} and {\tt G!equal}. We look back in
the inherited {\tt Couple} dependencies, we find {\tt S!rep},
{\tt S!rep} and {\tt T!equal}. So we construct the final dependencies
as {\tt S!rep[S<-G]} {\tt S!rep[S<-G]} and {\tt T!equal[T<-G]}



\subsubsection{Dependencies on collection parameters for record type}
Computing real dependencies on collection parameters for record type
is not clearly stated. For \ocaml, it is quite trivial since we don't
have any logical methods, hence we can only have dependencies via
``types''. For \ocaml, the situation is more tricky. In fact, due to
logical methods (theorems and properties), dependencies may more
complex, involving types and methods found in the expressions forming
the logical statements.

The same kind of problems arises than above (missing rule): an extra
rule is needed (the [DIDOU] rule), but the only difference is that
since the record type only shows ``types'', the initial set of
dependencies to close is the one obtained by the rule [TYPE].

It is not yet formally clear that computing dependencies required by
the record type is complete. Experiment seems to show that yes, but
further theorical investigations should be performed.

Taking a wider set of dependencies (for instance the same than those
computed method per method, all grouped in a single big union) would
lead to extra arguments (by $\lambda$-lifting) to the record type that
would not be used. This is unwanted for 2 reasons:
efficiency/readability of the generated code, and more importantly,
the risk to have variables not bound to a type, infered as
polymorphics, and for which \coq\ would say that it ``can't infer a
type for this placeholder''.



\subsection{Coq code generation model}
\subsubsection{The problem}
The initial \coq\ code generation model appeared to have a strong
weakness. Moreover, it was strongly different from the \ocaml\
one. Let's understand the weakness on a simple example\ldots The
problem is:

\begin{table}[h]
{\footnotesize
\begin{lstlisting}[emph={one}, emphstyle=\color{red},
                   emph={[2]lookatme}, emphstyle={[2]\color{blue}}]
species IntModel inherits Basic_object =
  representation = basics#int ;
  let one in Self = 1 ;
  let modulo (a, b) = if true then a else (if false then b else one) ;
end ;;

species Me (Naturals is IntModel, n in Naturals) =
  representation = Naturals ;

  theorem lookatme : all x in Self, basics#base_eq (n, Naturals!one)
    proof : assumed {* *} ;

  let reduce (x in Naturals) in Self = Naturals!modulo (x, n) ;
end ;;
\end{lstlisting}
}
\end{table}

The generated \coq\ code follows (at least, for the interesting part
of our problem, i.e. the {\tt lookatme} theorem):


\begin{table}[h]
{\footnotesize
\begin{lstlisting}[language=MyCoq,
                   emph={one, _p_Naturals_one}, emphstyle=\color{red},
                   emph={[2]lookatme, self_lookatme, Me__lookatme, Me_lookatme},
                     emphstyle={[2]\color{blue}}]
Chapter Me.
  Record Me (Naturals_T : Set) (_p_n_n : Naturals_T)
            (_p_Naturals_one : Naturals_T) : Type :=
    mk_Me {
      Me_T :> Set ;
      (* From species ok__in_example#Me. *)
      Me_lookatme :
        forall x : Me_T, Is_true ((basics.base_eq _ _p_n_n _p_Naturals_one)) ;
      (* From species ok__in_example#Me. *)
      Me_reduce : Naturals_T -> Me_T
      }.
 
  (* Variable abstracting the species parameter [Naturals]. *)
  Variable Naturals_T : Set.
  (* Variable abstracting the species parameter [n]. *)
  Variable n_n : Naturals_T.
 
  (* Carrier representation. *)
  Let self_T : Set := Naturals_T.
 
  (* Variable(s) induced by dependencies on methods from species
     parameter(s). *)
  Variable Naturals_modulo : Naturals_T -> Naturals_T -> Naturals_T.
  Variable Naturals_one : Naturals_T.
 
 
  (* From species ok__in_example#Me. *)
  Section lookatme.
    (* Due to a decl-dependency on species parameter carrier type 'Naturals'. *)
    Variable _p_Naturals_T : Set.
    (* Due to a decl-dependency on method 'one' of species parameter'Naturals'. *)
    Variable _p_Naturals_one : _p_Naturals_T.
    (* Due to a decl-dependency on method 'n' of species parameter 'n'. *)
    Variable _p_n_n : _p_Naturals_T.
    Theorem Me__lookatme :
      forall x : self_T, Is_true ((basics.base_eq _ _p_n_n _p_Naturals_one)).
    (* Artificial use of type 'Naturals_T' to ensure abstraction of it's
    related variable in the theorem section. *)
    assert (___force_abstraction_p_Naturals_T := _p_Naturals_T).
    (* Artificial use of method '_p_Naturals_one' to ensure abstraction of
    it's related variable in the theorem section. *)
    assert (___force_abstraction__p_Naturals_one := _p_Naturals_one).
    (* Artificial use of method '_p_n_n' to ensure abstraction of it's
    related variable in the theorem section. *)
    assert (___force_abstraction__p_n_n := _p_n_n).
    apply basics.magic_prove.
    Qed.
    End lookatme.

  Let self_lookatme :
    forall x : self_T, Is_true ((basics.base_eq _ n_n Naturals_one)) :=
    Me__lookatme Naturals_T Naturals_one n_n.

  ...
  End Me.
\end{lstlisting}
}
\end{table}

We see that there is a {\tt Section} for the species {\tt Me}. The
theorem {\color{blue}{\tt lookatme}} is in a nested {\tt Section}
({\tt Chapter} is a synonym for {\tt Section} in \coq).

It depends on {\color{red}{\tt one}} coming from {\tt Natural} (which is
a collection parameter), and on {\tt n} which is an entity parameter.

Hence, naturally, we will need to abstract these 3 things
({\color{red}{\tt one}}, {\tt n} and the type {\tt Natural}). This
really performed by the 4 {\tt Variable}s at the beginning of the
{\tt Section} {\color{blue}{\tt lookatme}}. Hence, looking at the type
of the {\bf theorem generator} {\color{blue}{\tt Me\_\_lookatme}}
{\bf inside} the {\tt Section} {\color{blue}{\tt lookatme}}, we see
that is has type:

\begin{table}[h]
{\footnotesize
\begin{lstlisting}[language=MyCoq,
                   emph={one, _p_Naturals_one}, emphstyle=\color{red},
                   emph={[2]Me__lookatme, Me_lookatme},
                     emphstyle={[2]\color{blue}}]
Me__lookatme:
  self_T -> Is_true (basics.base_eq _p_Naturals_T _p_n_n _p_Naturals_one)
\end{lstlisting}
}
\end{table}

\noindent since the {\tt Section} is not closed, because the
{\tt Variable}s are not yet abstracted by the \coq's {\tt Section}
mechanism.


We now close the {\tt Section}, then naturally the
{\bf theorem generator} {\color{blue}{\tt Me\_\_lookatme}} turns
having the type:

\begin{table}[h]
{\footnotesize
\begin{lstlisting}[language=MyCoq,
                   emph={one, _p_Naturals_one}, emphstyle=\color{red},
                   emph={[2]Me__lookatme, Me_lookatme},
                     emphstyle={[2]\color{blue}}]
Me__lookatme :
  forall (_p_Naturals_T : Set) (_p_Naturals_one _p_n_n : _p_Naturals_T),
    self_T -> Is_true (basics.base_eq _p_Naturals_T _p_n_n _p_Naturals_one)
\end{lstlisting}
}
\end{table}

Great ! the {\tt Variable}s have been abstracted for us by \coq. Now,
the idea is that this generator will be used to create a collection
like:

\begin{table}[h]
{\footnotesize
\begin{lstlisting}[emph={one}, emphstyle=\color{red},
                   emph={[2]Me}, emphstyle={[2]\color{blue}}]
collection ConcreteInt implements IntModel ;;
collection ConcreteMe implements Me (ConcreteInt, ConcreteInt!one) ;;
\end{lstlisting}
}
\end{table}

Let's continue and close the {\tt Chapter} ($\simeq$ a {\tt Section})
of species {\color{blue}{\tt Me}}. And then, here the theorem
generator {\color{blue}{\tt Me\_\_lookatme}} turns unfortunately to
have type:

\begin{table}[h]
{\footnotesize
\begin{lstlisting}[language=MyCoq,
                   emph={one, _p_Naturals_one}, emphstyle=\color{red},
                   emph={[2]Me__lookatme, Me_lookatme},
                     emphstyle={[2]\color{blue}}]
Me__lookatme:
  forall (Naturals_T _p_Naturals_T : Set)
    (_p_Naturals_one _p_n_n : _p_Naturals_T),
      Naturals_T ->
        Is_true (basics.base_eq _p_Naturals_T _p_n_n _p_Naturals_one)
\end{lstlisting}
}
\end{table}

\noindent We see that we have an extra {\tt Naturals\_T : Set} in

{\tt {\bf forall} (\underline{{\em Naturals\_T}} \_p\_Naturals\_T : Set) ...}

\noindent So now, we have 2 arguments of type {\tt Set}. Why ?

Let's have a look in the outer {\tt Section} related to the species
{\tt Me}. We had a {\tt Variable} already abstracting the type of the
collection parameter {\tt Natural}, namely
{\tt {\bf Variable} Natural\_T : Set}. And so, by closing the outer
{\tt Section} of the species {\tt Me}, \coq\ abstracted once
again. Then, it is the outer {\tt Section} that brings the problem,
not the inner one.

And obviously, this typing problem makes so that when we try to create
collection like above, we do not apply the method generator to the
number of arguments that \coq\ expects.

\medskip
A solution could be to say ``let's remove the
{\tt Variable Natural\_T : Set} from the outer {\tt Section}''. Right,
no ! Since we do not $\lambda$-lift in properties (generated as
{\tt Hypothesis} in \coq), if a \focalize\ property needs to make
reference to this type, we need a way to speak of if. And if we remove
it, then we are not able anymore to speak of it\ldots


\subsubsection{A few remarks}
\begin{itemize}
  \item The annoying {\tt Section} is then the outer one, the one of the
    species. Indeed, when we leave the inner {\tt Section}, the
    theorem gets right abstracted on the inner {\tt Variable}.

  \item This only arises on theorems because they are the only ones to
    be in a nested {\tt Section}.

  \item Moreover, we can note in this code generation model that the
    {\tt Local self\_xxx} are always generated even when the method
    {\tt xxx} is inherited. The reason is that since we do not
    $\lambda$-lift in properties (leading to \coq\ {\tt Hypothesis}),
    if a property depends on another method, it really need to have a
    way to speak of it in the property's statement. And namely, that's
    via this {\tt self\_xxx}.
    However, in the \ocaml\ code generation model, inherited methods
    are not generated again, hence do not lead to {\tt local\_xxx}
    definitions. This is not really homogeneous.
\end{itemize}


\subsubsection{Conclusion}
In order to solve this problem and to make \coq\ and \ocaml\ code
generation models (hence \coq\ and \ocaml\ generated codes), we
decided to use the same model, without {\tt Section}s and
{\tt Chapter}'s, and to manage abstractions ourselves via explicit
$\lambda$-liftings even for properties and theorems.

This raises a technical problem however since \zenon\ does not support
yet higher order. And in fact, with this generation model, out
theorems get parametrised by all the $\lambda$-lifted definitions. o
circumvent this problem, we decided to only reintroduce {\tt Section}s
in the code dedicated to be sent to \zenon, then map back the proved
theorems onto regular $\lambda$-lifted definitions. This means that on
\zenon's the point of view, there is no $\lambda$-lifts, all is first
order, and it can exhibit a proof. Once we get the proof done, we
apply it to the stated theorem in the {\tt Section} to get a temporary
version of the theorem. And finally, after closing the {\tt Section}
for \zenon, we transform this temporary version into a fully
$\lambda$-lifted definition.
