% $Id: scoping.tex,v 1.2 2009-04-22 15:59:00 pessaux Exp $
The scoping process aims to link each identifier occurrence to its
related definition according to the rules that drive the visibility of
identifers. It avoids name confusion and ensure that each occurrence
of identifier refers to one and one unique effective definition.

Ideally, once scoped, a program shoud have unique names for each
identifier (i.e. a name plus a stamp that ensure the unicity). For
example in the following piece of code:
{\footnotesize
\begin{lstlisting}
let y = 0 ;;
let x =
  let x = 1 in
  let x = x + 1 in
  let y = x + x in
  y + x in
y + x ;;
\end{lstlisting}
}
scoping rules allow to uniquely identify identifiers by renaming them
in:
{\footnotesize
\begin{lstlisting}
let y_0 = 0 ;;
let x_0 =
  let x_1 = 1 in
  let x_2 = x_1 + 1 in
  let y_1 = x_2 + x_2 in
  y_1 + x_2 in
y_0 + x_0 ;;
\end{lstlisting}
}

This way, each occurrence has a clearly identified definition since if
two identifiers have the same name then they refer to the same
definition. Moreover, this ensure that all the occurrences have one
and opne unique related definition, hence preventing unbound
identifiers.

In \focalize, we do not rename the identifiers with indices. Instead,
we make they qualification explicit. The case where twho identifiers
with the same qualification are present is handled by the environment
mechanism that will hide the oldest identifier definition by the
newest according to their order in the source code. In fact, in the
case of toplevel definitions in a same compilation unit and methods in
a same species, the environment mechanism refuses to have several
times the same names. This is not a technical problem, this is only a
choice to prevent the programmer from masking these fundamental kind
of definitions.

Hence the output of the scoping pass is an AST where all the
identifiers occurrences received a qualification if they are not
locally bound. This means that by default, the parser must parse
identifiers that are not qualified (i.e. with no \#-notation and/or no
!-notation) as {\bf local identifiers} (i.e. as
{\tt Parsetree.I\_local}). This means that during scoping, only
{\tt Parsetree.I\_local} identifiers will be affected by the scoping
transformation. Local identifiers will be looked-up to determine
whether they are really local or are method names or toplevel (of a
file) names. The transformation is not performed in place. Instead, we
return a fresh AST (still possibly having sharing with the original
one) that will be suitable for the typechecking phase.

For identifiers already disamguated by the parser, there are 2 cases:
``\#-ed'' and ``!-ed'' identifiers. The scoper will still work by
ensuring that these identifiers are really related to an existing
definition.
\begin{itemize}
\item For ``\#-ed'' identifiers, the look-up is performed and they are
  always explicitly replaced with the name of the hosting file where
  they are bound. Hence in a current compilation unit ``Kikoo''", then
  {\tt \#test ()} will be replaced by {\tt Kikoo\#test ()} if the
  function {\tt test} was really found inside this unit. If it was not
  found, then an exception is raised.

\item For ``!-ed'' identifiers, the look-up is performed but no change
  is done. If it is like {\tt !test()}, then it is {\bf not} changed to
  {\tt Self!test} !!! Only a verification is done that the method
  exists in {\tt Self}. If it is like {\tt Coll!test}, then also only
  a verification is done that the method exists in {\tt Coll}.
\end{itemize}

The scoping heavily uses the ``scoping environment'' structure
described in \ref{scoping-environment-presentation}. Scoping is
performed on each phrase of the source text, in the order of
apparition of these phrases. Hence we have to scope phrases amongt
documentation title, {\tt use} directive, {\tt open} directive,
{\tt coq\_require} directive, species definition, collection
definition, type definition, toplevel value definition, toplevel
therorem definition and toplevel expression. For each scoped phrase,
the {\bf new environment} made of the initially received one extended
by the new scoped definitions is returned. We don't return only a
delta: we return a complete usable new environment.

Most of the scoping functions use a parameter named a
``context''. This structure is intended to group into 1 unique
parameter various values (that would otherwise be as many parameters)
the scoping functions will mostly always use.
{\footnotesize
\begin{lstlisting}[language=MyOCaml]
type scoping_context = {
  (** The name of the currently analysed compilation unit. *)
  current_unit : Types.fname ;
  (** The optional name of the currently analysed species. *)
  current_species : string option ;
  (** The list of "use"-d (or open-ed since "open" implies "use") modules.
      Not file with paths and extension : just module name (ex: "basics"). *)
  used_modules : Types.fname list
} ;;
\end{lstlisting}
}


\subsection{Scoping an {\tt use} directive}
Scoping a {\tt use} directive returns un unchanged environment.
It simply adds the ``used'' module to the list modules allowed to be
used of the current context and return a new context with this
extended list. The point is only to mention for the rest of the
scoping passe that qualified identifiers with this module as
qualification is now allowed.


\subsection{Scoping an {\tt open} directive}
This directive has no to be really scoped. Instead, it has an impact
on the scoping process and more accurately on the scoping environment.
In load in the environment the scoping information of the identifiers
contained in the opened compilation unit, tagging then as
{\tt BO\_opened} like seen in \ref{tag-BO-opened}. Hence all the
imported identifiers will be known as possible definitions to use as
``origin'' of an identifier occurrence, according to the scoping
rules.


\subsection{Scoping a species definition}
Before scoping a species, the first thing is to pass a modified
context in which we record that we are inside this species (field
{\tt current\_species} on the context.

The scoping environment of a species will be gradually extended as
long as we process its components: we must first add the parameters of
collection and entity in their order of apparition then import the
bindings from the inheritance tree, and finally local bindings will be
added while scoping the species' body (fields). Scoping must be done
by searching in the environment in the following order:
\begin{enumerate}
\item Try to find the identifier in local environment.
\item Check if it's a parameter of entity (``{\tt in}'') or collection
  (``{\tt is}'').
\item Try to find the identifier throughout the hierarchy.
\item Try to find the identifier is a global identifier..
\item ``Else'' \ldots not found !
\end{enumerate}
So the order in which the identifiers are inserted into the
environment used to scope the species must respect extentions in the
reverse order in order to find the most recently added bindings first.

Hence we first scope the species parameters. Once they are scoped, we
get an environment where they are bound to their scoping information.

Using this new environment, we now scope the {\tt inherits} clause,
i.e. the inheritance. In addition to the scoped inheritance
expression, this will give us bake the names of the methods we
inherits. This is especially usefull because we must add them into our
environment before scoping the methods defined in this
species. Indeedn the bodies od these defined may make reference to
identifiers corresponding to inherited methods.

\subsection{Scoping a collection definition}

\subsection{Scoping a type definition}

\subsection{Scoping a toplevel value definition}

\subsection{Scoping a toplevel theorem definition}

\subsection{Scoping a toplevel expression}
There nothing special to say on this point. Scoping is done like for
any expression we already spoke about. It can be noticed that since
the toplevel is not bound to an identifier, the returned scoping
environment remains unchanged. The returned context is also
unchanged.